{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Need to move TRANSFORMERS and text_to_code_q6 to other script\n",
    "from build_model_multinomial import TRANSFORMERS, text_to_code_q6, text_to_code_q10_2_binary, fallback_text_to_float, text_to_code_q10_2_binary_exclude_neither\n",
    "from build_model_logistic import build_v2g_model_binary_from_df\n",
    "from get_data import init_column_map, pull_data_rowwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all variable categories\n",
    "from variables import (\n",
    "    demographics, \n",
    "    input_variables_vehicle_ownership, \n",
    "    familiarity, \n",
    "    kms_driven, \n",
    "    renewables_at_home,\n",
    "    parking, \n",
    "    q6a_cols, \n",
    "    energ_literacy, \n",
    "    renewables_at_home, \n",
    "    intent_to_purchase_vehicle,\n",
    "    benefits_v2g, \n",
    "    concerns_v2g, \n",
    "    interest_in_services, \n",
    "    consider_using_NRMA_for,\n",
    "    charging_control, \n",
    "    preference_on_batt_use, \n",
    "    expected_return,\n",
    "    q6a_petrol, q6a_ev, q6a_plughyb, q6a_hybrid,\n",
    "    charging_control,\n",
    "    feature_label_map\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Initialise dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = './data/survey_pre_processed_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = 'Q10_2'  # \"I would be interested in installing V2G...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "q10_2_categories = [\n",
    "    \"Strongly disagree\",\n",
    "    \"Somewhat disagree\",\n",
    "    \"Neither agree nor disagree\",\n",
    "    \"Somewhat agree\",\n",
    "    \"Strongly agree\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q8_1</th>\n",
       "      <th>Q8_2</th>\n",
       "      <th>Q8_99</th>\n",
       "      <th>Q6ax1_1</th>\n",
       "      <th>Q6ax1_2</th>\n",
       "      <th>Q6ax1_3</th>\n",
       "      <th>Q6ax2_1</th>\n",
       "      <th>Q6ax2_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Q15_9</th>\n",
       "      <th>Q15_10</th>\n",
       "      <th>Q15_99</th>\n",
       "      <th>Q7_1</th>\n",
       "      <th>Q7_2</th>\n",
       "      <th>Q7_3</th>\n",
       "      <th>Q17_1</th>\n",
       "      <th>Q17_2</th>\n",
       "      <th>Q17_3</th>\n",
       "      <th>Q10_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Somewhat familiar</td>\n",
       "      <td>Less than 10,000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Neither agree nor disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Very familiar</td>\n",
       "      <td>Less than 10,000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Strongly agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not at all familiar</td>\n",
       "      <td>20,001-50,000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Strongly disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not at all familiar</td>\n",
       "      <td>Less than 10,000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Somewhat disagree</td>\n",
       "      <td>Somewhat disagree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Somewhat disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very familiar</td>\n",
       "      <td>20,001-50,000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Somewhat agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>Somewhat familiar</td>\n",
       "      <td>10,000-20,000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Neither agree nor disagree</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Strongly agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>Somewhat familiar</td>\n",
       "      <td>Less than 10,000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Neither agree nor disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>Very familiar</td>\n",
       "      <td>10,000-20,000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Neither agree nor disagree</td>\n",
       "      <td>Neither agree nor disagree</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Strongly agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>Very familiar</td>\n",
       "      <td>10,000-20,000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither agree nor disagree</td>\n",
       "      <td>Neither agree nor disagree</td>\n",
       "      <td>Neither agree nor disagree</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Somewhat agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>Very familiar</td>\n",
       "      <td>20,001-50,000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Somewhat disagree</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Strongly disagree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1358 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Q9                Q2 Q8_1 Q8_2 Q8_99 Q6ax1_1 Q6ax1_2  \\\n",
       "0       Somewhat familiar  Less than 10,000    1    0     0       3       5   \n",
       "1           Very familiar  Less than 10,000    1    1     0       5       5   \n",
       "2     Not at all familiar     20,001-50,000    0    0     1       2       1   \n",
       "3     Not at all familiar  Less than 10,000    0    0     1                   \n",
       "4           Very familiar     20,001-50,000    1    1     0       5       5   \n",
       "...                   ...               ...  ...  ...   ...     ...     ...   \n",
       "1353    Somewhat familiar     10,000-20,000    1    1     0                   \n",
       "1354    Somewhat familiar  Less than 10,000    0    0     1       5       5   \n",
       "1355        Very familiar     10,000-20,000    1    0     0       4       4   \n",
       "1356        Very familiar     10,000-20,000    0    0     1                   \n",
       "1357        Very familiar     20,001-50,000    1    1     0                   \n",
       "\n",
       "     Q6ax1_3 Q6ax2_1 Q6ax2_2  ... Q15_9 Q15_10 Q15_99  \\\n",
       "0          5                  ...     0      0      0   \n",
       "1          5       5       5  ...     0      0      1   \n",
       "2          2                  ...     0      0      0   \n",
       "3                             ...     0      0      0   \n",
       "4          5       4       4  ...     0      0      0   \n",
       "...      ...     ...     ...  ...   ...    ...    ...   \n",
       "1353               1       3  ...     0      0      0   \n",
       "1354       5                  ...     0      1      0   \n",
       "1355       5       4       4  ...     0      1      0   \n",
       "1356               3       5  ...     0      1      0   \n",
       "1357               2       5  ...     1      1      0   \n",
       "\n",
       "                            Q7_1                        Q7_2  \\\n",
       "0                 Somewhat agree              Somewhat agree   \n",
       "1                 Strongly agree              Strongly agree   \n",
       "2                 Somewhat agree              Somewhat agree   \n",
       "3              Somewhat disagree           Somewhat disagree   \n",
       "4                 Strongly agree              Strongly agree   \n",
       "...                          ...                         ...   \n",
       "1353              Strongly agree              Strongly agree   \n",
       "1354              Strongly agree              Somewhat agree   \n",
       "1355              Strongly agree  Neither agree nor disagree   \n",
       "1356  Neither agree nor disagree  Neither agree nor disagree   \n",
       "1357              Strongly agree              Somewhat agree   \n",
       "\n",
       "                            Q7_3 Q17_1 Q17_2 Q17_3                       Q10_2  \n",
       "0                 Somewhat agree     2     3     1  Neither agree nor disagree  \n",
       "1                 Somewhat agree     2     1     3              Strongly agree  \n",
       "2                 Somewhat agree                             Strongly disagree  \n",
       "3                 Somewhat agree     3     1     2           Somewhat disagree  \n",
       "4                 Somewhat agree     2     1     3              Somewhat agree  \n",
       "...                          ...   ...   ...   ...                         ...  \n",
       "1353  Neither agree nor disagree     1     3     2              Strongly agree  \n",
       "1354              Somewhat agree     3     2     1  Neither agree nor disagree  \n",
       "1355  Neither agree nor disagree     2     1     3              Strongly agree  \n",
       "1356  Neither agree nor disagree     2     1     3              Somewhat agree  \n",
       "1357           Somewhat disagree                             Strongly disagree  \n",
       "\n",
       "[1358 rows x 62 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull the data from CSV\n",
    "init_column_map(csv_file)\n",
    "\n",
    "# TBD -> Make function here\n",
    "columns_of_interest = (\n",
    "    familiarity +\n",
    "    kms_driven + \n",
    "    renewables_at_home + \n",
    "    q6a_cols + \n",
    "    demographics + \n",
    "    input_variables_vehicle_ownership + \n",
    "    parking + \n",
    "    benefits_v2g + \n",
    "    concerns_v2g +\n",
    "    energ_literacy +\n",
    "    charging_control +\n",
    "    [target_variable]\n",
    "    )\n",
    "\n",
    "rows = pull_data_rowwise(columns_of_interest, csv_file)\n",
    "\n",
    "# Make a DataFrame\n",
    "df = pd.DataFrame(rows, columns=columns_of_interest)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in Q6ax1_1: [3. 5. 2. 4. 0. 1.]\n",
      "Unique values in Q6ax1_2: [5. 1. 3. 2. 4. 0.]\n",
      "Unique values in Q6ax1_3: [5. 2. 0. 4. 3. 1.]\n",
      "Unique values in Q6ax2_1: [5. 4. 3. 1. 2. 0.]\n",
      "Unique values in Q6ax2_2: [5. 4. 3. 2. 0. 1.]\n",
      "Unique values in Q6ax2_3: [5. 4. 3. 1. 0. 2.]\n",
      "Unique values in Q6ax3_1: [3. 1. 4. 0. 2. 5.]\n",
      "Unique values in Q6ax3_2: [5. 4. 2. 3. 1.]\n",
      "Unique values in Q6ax3_3: [5. 2. 3. 4.]\n",
      "Unique values in Q6ax4_1: [0. 2. 5. 4. 3. 1.]\n",
      "Unique values in Q6ax4_2: [5. 2. 3. 0. 4. 1.]\n",
      "Unique values in Q6ax4_3: [5. 3. 0. 1. 4. 2.]\n"
     ]
    }
   ],
   "source": [
    "# Ensure \"0 - Weekdays\" is converted correctly\n",
    "for col in q6a_cols:\n",
    "    df[col] = df[col].replace(\"0 - Weekdays\", 0)  # Convert \"0 - Weekdays\" to 0\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')  # Convert all values to numbers\n",
    "\n",
    "# Debugging: Check unique values in each column\n",
    "for col in q6a_cols:\n",
    "    print(f\"Unique values in {col}: {df[col].dropna().unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of responses recorded as 0:\n",
      "Q6ax1_1    118\n",
      "Q6ax1_2     28\n",
      "Q6ax1_3     31\n",
      "Q6ax2_1    102\n",
      "Q6ax2_2     24\n",
      "Q6ax2_3     14\n",
      "Q6ax3_1      4\n",
      "Q6ax3_2      0\n",
      "Q6ax3_3      0\n",
      "Q6ax4_1     12\n",
      "Q6ax4_2      6\n",
      "Q6ax4_3      9\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count missing responses for each charging question\n",
    "missing_counts = (df[q6a_cols] == 0).sum()\n",
    "# Display summary of non-responses per column\n",
    "print(\"Number of responses recorded as 0:\")\n",
    "print(missing_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q6ax1_1    874\n",
      "Q6ax1_2    874\n",
      "Q6ax1_3    874\n",
      "Q6ax2_1    768\n",
      "Q6ax2_2    768\n",
      "Q6ax2_3    768\n",
      "Q6ax3_1     33\n",
      "Q6ax3_2     33\n",
      "Q6ax3_3     33\n",
      "Q6ax4_1    111\n",
      "Q6ax4_2    111\n",
      "Q6ax4_3    111\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking number of vehicles per type\n",
    "print(df[q6a_petrol + q6a_ev + q6a_plughyb + q6a_hybrid].notna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Update transformers to consider Q10_2 as binary (other than multinomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of TRANSFORMERS and update it with Q6a mappings\n",
    "TRANSFORMERS_q6a = TRANSFORMERS.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update with Q6a_* variables (charging behavior questions)\n",
    "TRANSFORMERS_q6a.update({\n",
    "    **{q: text_to_code_q6 for q in q6a_petrol},  \n",
    "    **{q: text_to_code_q6 for q in q6a_ev},      \n",
    "    **{q: text_to_code_q6 for q in q6a_plughyb}, \n",
    "    **{q: text_to_code_q6 for q in q6a_hybrid}   \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1_1': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q1_2': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q1_3': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q1_4': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q1_99': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q2': <function build_model_multinomial.text_to_code_q2(raw_ans)>,\n",
       " 'Q3_1': <function build_model_multinomial.text_to_code_q3_parking(raw_ans)>,\n",
       " 'Q3_2': <function build_model_multinomial.text_to_code_q3_parking(raw_ans)>,\n",
       " 'Q3_3': <function build_model_multinomial.text_to_code_q3_parking(raw_ans)>,\n",
       " 'Q3_4': <function build_model_multinomial.text_to_code_q3_parking(raw_ans)>,\n",
       " 'Q3_5': <function build_model_multinomial.text_to_code_q3_parking(raw_ans)>,\n",
       " 'Q7_1': <function build_model_multinomial.text_to_code_q7_likert(raw_ans)>,\n",
       " 'Q7_2': <function build_model_multinomial.text_to_code_q7_likert(raw_ans)>,\n",
       " 'Q7_3': <function build_model_multinomial.text_to_code_q7_likert(raw_ans)>,\n",
       " 'Q8_1': <function build_model_multinomial.text_to_code_q8_multi(raw_ans)>,\n",
       " 'Q8_2': <function build_model_multinomial.text_to_code_q8_multi(raw_ans)>,\n",
       " 'Q8_99': <function build_model_multinomial.text_to_code_q8_multi(raw_ans)>,\n",
       " 'Q9': <function build_model_multinomial.text_to_code_q9(raw_ans)>,\n",
       " 'Q10_2': <function build_model_multinomial.text_to_code_q10_2_binary(raw_ans)>,\n",
       " 'Q14_1': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q14_2': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q14_3': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q14_4': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q14_5': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q14_6': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q14_7': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q14_8': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q14_99': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q15_1': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q15_2': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q15_3': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q15_4': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q15_5': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q15_6': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q15_7': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q15_8': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q15_9': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q15_10': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q15_99': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q17_1': <function build_model_multinomial.text_to_code_q17_rank(raw_ans)>,\n",
       " 'Q17_2': <function build_model_multinomial.text_to_code_q17_rank(raw_ans)>,\n",
       " 'Q17_3': <function build_model_multinomial.text_to_code_q17_rank(raw_ans)>,\n",
       " 'Q6ax1_1': <function build_model_multinomial.text_to_code_q6(raw_ans)>,\n",
       " 'Q6ax1_2': <function build_model_multinomial.text_to_code_q6(raw_ans)>,\n",
       " 'Q6ax1_3': <function build_model_multinomial.text_to_code_q6(raw_ans)>,\n",
       " 'Q6ax2_1': <function build_model_multinomial.text_to_code_q6(raw_ans)>,\n",
       " 'Q6ax2_2': <function build_model_multinomial.text_to_code_q6(raw_ans)>,\n",
       " 'Q6ax2_3': <function build_model_multinomial.text_to_code_q6(raw_ans)>,\n",
       " 'Q6ax3_1': <function build_model_multinomial.text_to_code_q6(raw_ans)>,\n",
       " 'Q6ax3_2': <function build_model_multinomial.text_to_code_q6(raw_ans)>,\n",
       " 'Q6ax3_3': <function build_model_multinomial.text_to_code_q6(raw_ans)>,\n",
       " 'Q6ax4_1': <function build_model_multinomial.text_to_code_q6(raw_ans)>,\n",
       " 'Q6ax4_2': <function build_model_multinomial.text_to_code_q6(raw_ans)>,\n",
       " 'Q6ax4_3': <function build_model_multinomial.text_to_code_q6(raw_ans)>}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORMERS_q6a[target_variable] = text_to_code_q10_2_binary\n",
    "TRANSFORMERS_q6a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Selection - Univariate Logistic Regression Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_select = (\n",
    "    familiarity + \n",
    "    kms_driven +\n",
    "    renewables_at_home +\n",
    "    input_variables_vehicle_ownership + \n",
    "    q6a_petrol + \n",
    "    q6a_ev + \n",
    "    q6a_hybrid +\n",
    "    q6a_plughyb +\n",
    "    parking +\n",
    "    benefits_v2g + \n",
    "    concerns_v2g + \n",
    "    charging_control +\n",
    "    energ_literacy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[target_variable] = df[target_variable].apply(text_to_code_q10_2_binary)\n",
    "\n",
    "# Ensure the target variable is binary (0 or 1)\n",
    "df[target_variable] = df[target_variable].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Vehicle at home habits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per Q6a variable:\n",
      " Q6ax1_1     484\n",
      "Q6ax1_2     484\n",
      "Q6ax1_3     484\n",
      "Q6ax2_1     590\n",
      "Q6ax2_2     590\n",
      "Q6ax2_3     590\n",
      "Q6ax3_1    1325\n",
      "Q6ax3_2    1325\n",
      "Q6ax3_3    1325\n",
      "Q6ax4_1    1247\n",
      "Q6ax4_2    1247\n",
      "Q6ax4_3    1247\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_q6a = df[q6a_cols].isna().sum()\n",
    "print(\"Missing values per Q6a variable:\\n\", missing_q6a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[q6a_cols] = df[q6a_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in Q6ax1_1: [3. 5. 2. 0. 4. 1.]\n",
      "Unique values in Q6ax1_2: [5. 1. 0. 3. 2. 4.]\n",
      "Unique values in Q6ax1_3: [5. 2. 0. 4. 3. 1.]\n",
      "Unique values in Q6ax2_1: [0. 5. 4. 3. 1. 2.]\n",
      "Unique values in Q6ax2_2: [0. 5. 4. 3. 2. 1.]\n",
      "Unique values in Q6ax2_3: [0. 5. 4. 3. 1. 2.]\n",
      "Unique values in Q6ax3_1: [0. 3. 1. 4. 2. 5.]\n",
      "Unique values in Q6ax3_2: [0. 5. 4. 2. 3. 1.]\n",
      "Unique values in Q6ax3_3: [0. 5. 2. 3. 4.]\n",
      "Unique values in Q6ax4_1: [0. 2. 5. 4. 3. 1.]\n",
      "Unique values in Q6ax4_2: [0. 5. 2. 3. 4. 1.]\n",
      "Unique values in Q6ax4_3: [0. 5. 3. 1. 4. 2.]\n"
     ]
    }
   ],
   "source": [
    "for col in q6a_cols:\n",
    "    print(f\"Unique values in {col}: {df[col].dropna().unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "q6a_filters = {\n",
    "    \"petrol\": (df[\"Q1_1\"].astype(int) == 1),\n",
    "    \"ev\": (df[\"Q1_2\"].astype(int) == 1),\n",
    "    \"plug_hybrid\": (df[\"Q1_3\"].astype(int) == 1),\n",
    "    \"hybrid\": (df[\"Q1_4\"].astype(int) == 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Logistic Regression for: Q9\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q2\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q8_1\n",
      "Valid rows are 1358\n",
      "Skipping Q8_1 (constant value: 1.0)\n",
      "Running Logistic Regression for: Q8_2\n",
      "Valid rows are 1358\n",
      "Skipping Q8_2 (constant value: 1.0)\n",
      "Running Logistic Regression for: Q8_99\n",
      "Valid rows are 1358\n",
      "Skipping Q8_99 (constant value: 1.0)\n",
      "Running Logistic Regression for: Q1_1\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q1_2\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q1_3\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q1_4\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q1_99\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q6ax1_1\n",
      "Valid rows are 874\n",
      "Running Logistic Regression for: Q6ax1_2\n",
      "Valid rows are 874\n",
      "Running Logistic Regression for: Q6ax1_3\n",
      "Valid rows are 874\n",
      "Running Logistic Regression for: Q6ax2_1\n",
      "Valid rows are 768\n",
      "Running Logistic Regression for: Q6ax2_2\n",
      "Valid rows are 768\n",
      "Running Logistic Regression for: Q6ax2_3\n",
      "Valid rows are 768\n",
      "Running Logistic Regression for: Q6ax4_1\n",
      "Valid rows are 111\n",
      "Running Logistic Regression for: Q6ax4_2\n",
      "Valid rows are 111\n",
      "Running Logistic Regression for: Q6ax4_3\n",
      "Valid rows are 111\n",
      "Running Logistic Regression for: Q6ax3_1\n",
      "Valid rows are 33\n",
      "Running Logistic Regression for: Q6ax3_2\n",
      "Valid rows are 33\n",
      "Running Logistic Regression for: Q6ax3_3\n",
      "Valid rows are 33\n",
      "Running Logistic Regression for: Q3_1\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q3_2\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q3_3\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q3_4\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q3_5\n",
      "Valid rows are 1358\n",
      "Skipping Q3_5 (constant value: 0)\n",
      "Running Logistic Regression for: Q14_1\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q14_2\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q14_3\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q14_4\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q14_5\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q14_6\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q14_7\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q14_8\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q14_99\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q15_1\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q15_2\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q15_3\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q15_4\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q15_5\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q15_6\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q15_7\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q15_8\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q15_9\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q15_10\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q15_99\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q17_1\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q17_2\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q17_3\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q7_1\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q7_2\n",
      "Valid rows are 1358\n",
      "Running Logistic Regression for: Q7_3\n",
      "Valid rows are 1358\n"
     ]
    }
   ],
   "source": [
    "# Initialize list to store results\n",
    "results = []\n",
    "\n",
    "# Loop through each feature in features_to_select\n",
    "for feature in features_to_select:\n",
    "    print(f\"Running Logistic Regression for: {feature}\")\n",
    "\n",
    "    # Ensure the feature exists in the dataframe\n",
    "    if feature not in df.columns:\n",
    "        print(f\"Skipping {feature} (not in dataframe)\")\n",
    "        continue\n",
    "\n",
    "    # Apply appropriate filters based on the type of vehicle\n",
    "    if feature in q6a_petrol:\n",
    "        filtered_df = df[q6a_filters[\"petrol\"]]\n",
    "    elif feature in q6a_ev:\n",
    "        filtered_df = df[q6a_filters[\"ev\"]]\n",
    "    elif feature in q6a_plughyb:\n",
    "        filtered_df = df[q6a_filters[\"plug_hybrid\"]]\n",
    "    elif feature in q6a_hybrid:\n",
    "        filtered_df = df[q6a_filters[\"hybrid\"]]\n",
    "    else:\n",
    "        filtered_df = df  # Default (includes all data)\n",
    "\n",
    "    # Ensure enough data is available for analysis\n",
    "    if filtered_df.shape[0] < 10:  # Skip if too few respondents\n",
    "        print(f\"Skipping {feature} (too few valid rows: {filtered_df.shape[0]})\")\n",
    "        continue\n",
    "\n",
    "    # Convert feature using transformer if available, otherwise cast to numeric\n",
    "    if feature in TRANSFORMERS_q6a:\n",
    "        X_single = filtered_df[feature].apply(TRANSFORMERS_q6a[feature])\n",
    "    else:\n",
    "        X_single = pd.to_numeric(filtered_df[feature], errors=\"coerce\")  # Convert safely\n",
    "\n",
    "    # Drop NaN values\n",
    "    valid_rows = ~X_single.isna()\n",
    "\n",
    "    print(f\"Valid rows are {valid_rows.count()}\")\n",
    "    \n",
    "    X_single = X_single[valid_rows].values.reshape(-1, 1)\n",
    "    y = filtered_df.loc[valid_rows, target_variable].values  # Ensure target aligns with valid rows\n",
    "\n",
    "    # Check if feature has only one unique value\n",
    "    if len(np.unique(X_single)) == 1:\n",
    "        print(f\"Skipping {feature} (constant value: {np.unique(X_single)[0]})\")\n",
    "        continue\n",
    "\n",
    "    # Fit logistic regression\n",
    "    model = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "    model.fit(X_single, y)\n",
    "\n",
    "    # Predict & evaluate performance\n",
    "    y_pred = model.predict(X_single)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "\n",
    "    # Get coefficient & odds ratio\n",
    "    coef = model.coef_[0][0]\n",
    "    odds_ratio = np.exp(coef)\n",
    "\n",
    "    # Fit logistic regression using statsmodels for p-value\n",
    "    X_with_intercept = sm.add_constant(X_single)\n",
    "    sm_model = sm.Logit(y, X_with_intercept).fit(disp=0)  # Suppress verbose output\n",
    "    p_value = sm_model.pvalues[1]  # Extract p-value for feature\n",
    "\n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"Feature\": feature_label_map.get(feature, feature),  # Use full label if available\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Coefficient\": coef,\n",
    "        \"Odds Ratio\": odds_ratio,\n",
    "        \"P-value\": p_value\n",
    "    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort by strongest effect (absolute coefficient)\n",
    "results_df[\"abs_coef\"] = results_df[\"Coefficient\"].abs()\n",
    "results_df = results_df.sort_values(by=\"abs_coef\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(results_df[\"P-value\"], results_df[\"abs_coef\"], alpha=0.7)\n",
    "plt.axvline(x=0.05, color=\"red\", linestyle=\"--\", label=\"Significance Threshold (0.05)\")\n",
    "plt.xlabel(\"P-value\")\n",
    "plt.ylabel(\"Absolute Coefficient\")\n",
    "plt.title(\"Feature Significance vs. Effect Size\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sort by absolute coefficient value\n",
    "results_df_sorted = results_df.sort_values(by=\"abs_coef\", ascending=True)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 16))\n",
    "plt.barh(results_df_sorted[\"Feature\"], results_df_sorted[\"Coefficient\"], color=[\"green\" if x > 0 else \"red\" for x in results_df_sorted[\"Coefficient\"]])\n",
    "plt.axvline(0, color=\"black\", linewidth=1)  # Add a vertical line at 0 for reference\n",
    "plt.xlabel(\"Coefficient\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Influence on V2G Adoption (Logistic Regression)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by odds ratio\n",
    "results_df_sorted = results_df.sort_values(by=\"Odds Ratio\", ascending=False)\n",
    "\n",
    "# Create a figure\n",
    "plt.figure(figsize=(16, 10))\n",
    "\n",
    "# Plot a horizontal bar chart of odds ratios\n",
    "sns.barplot(\n",
    "    data=results_df_sorted, \n",
    "    x='Odds Ratio', \n",
    "    y='Feature', \n",
    "    orient='h',  # horizontal bars\n",
    "    palette='crest'  # single color for all bars\n",
    ")\n",
    "\n",
    "# Add a vertical reference line at x=1 (odds ratio = 1 implies no effect)\n",
    "plt.axvline(x=1, color='red', linestyle='--', linewidth=1)\n",
    "\n",
    "# Improve labels/titles\n",
    "plt.xlabel('Odds Ratio')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Odds Ratios for Logistic Regression Features')\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sort by p-value\n",
    "results_df_sorted = results_df.sort_values(by=\"P-value\", ascending=True)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 12))\n",
    "plt.barh(results_df_sorted[\"Feature\"], results_df_sorted[\"P-value\"], color=[\"blue\" if p < 0.05 else \"gray\" for p in results_df_sorted[\"P-value\"]])\n",
    "plt.axvline(0.05, color=\"red\", linestyle=\"dashed\", linewidth=1.5, label=\"Significance Threshold (p=0.05)\")\n",
    "plt.xlabel(\"P-Value\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Significance (P-Values)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 12))\n",
    "plt.barh(results_df_sorted[\"Feature\"], np.log10(results_df_sorted[\"P-value\"]), color=[\"blue\" if p < 0.05 else \"gray\" for p in results_df_sorted[\"P-value\"]])\n",
    "plt.axvline(np.log10(0.05), color=\"red\", linestyle=\"dashed\", linewidth=1.5, label=\"Significance Threshold (log10 p=0.05)\")\n",
    "plt.xlabel(\"Log10 P-Value\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Significance (Log-Scaled P-Values)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute -log(p-value) for better visualization\n",
    "results_df[\"-log(p)\"] = -np.log10(results_df[\"P-value\"])\n",
    "\n",
    "# Define colors based on significance threshold (p < 0.05)\n",
    "colors = [\"blue\" if p < 0.05 else \"gray\" for p in results_df[\"P-value\"]]\n",
    "\n",
    "# Create scatter plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(results_df[\"Coefficient\"], results_df[\"-log(p)\"], c=colors, edgecolors=\"black\")\n",
    "\n",
    "# Add labels for key points\n",
    "for i, txt in enumerate(results_df[\"Feature\"]):\n",
    "    plt.annotate(txt, (results_df[\"Coefficient\"].iloc[i], results_df[\"-log(p)\"].iloc[i]), fontsize=9, alpha=0.7)\n",
    "\n",
    "# Reference lines\n",
    "plt.axvline(0, color=\"black\", linestyle=\"--\", linewidth=1)  # Vertical line at zero coefficient\n",
    "plt.axhline(-np.log10(0.05), color=\"red\", linestyle=\"--\", linewidth=1, label=\"p=0.05 threshold\")  # Horizontal line at p=0.05\n",
    "\n",
    "# Labels & title\n",
    "plt.xlabel(\"Coefficient\")\n",
    "plt.ylabel(\"-log10(P-value)\")\n",
    "plt.title(\"Feature Influence on V2G Adoption (Coefficient vs Significance)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sort by absolute coefficient value\n",
    "results_df_sorted = results_df.sort_values(by=\"abs_coef\", ascending=True)\n",
    "\n",
    "# Define colors: Gray for p >= 0.05, Green for positive, Red for negative\n",
    "colors = [\n",
    "    \"gray\" if p >= 0.05 else (\"green\" if coef > 0 else \"red\")\n",
    "    for p, coef in zip(results_df_sorted[\"P-value\"], results_df_sorted[\"Coefficient\"])\n",
    "]\n",
    "\n",
    "# Create figure\n",
    "plt.figure(figsize=(12, 18))\n",
    "bars = plt.barh(results_df_sorted[\"Feature\"], results_df_sorted[\"Coefficient\"], color=colors)\n",
    "\n",
    "# Add p-value annotations on the right side\n",
    "for bar, p_value in zip(bars, results_df_sorted[\"P-value\"]):\n",
    "    plt.text(bar.get_width() + 0.1, bar.get_y() + bar.get_height()/2, f\"p={p_value:.3g}\", va='center', fontsize=10)\n",
    "\n",
    "# Reference line at zero\n",
    "plt.axvline(0, color=\"black\", linewidth=1, linestyle=\"--\")\n",
    "\n",
    "# Labels and title\n",
    "plt.xlabel(\"Coefficient\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Influence on V2G Adoption (Logistic Regression)\\n(Non-significant features greyed out)\")\n",
    "plt.tight_layout()  # Adjust layout to prevent text cutoff\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Binomial Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Filtering my df based on the previous p-value analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of significant features (p < 0.05)\n",
    "significant_features = results_df[results_df[\"P-value\"] < 0.05][\"Feature\"].tolist()\n",
    "\n",
    "# Map back to original column names using feature_label_map\n",
    "significant_columns = [key for key, value in feature_label_map.items() if value in significant_features]\n",
    "\n",
    "# Ensure the target variable is retained\n",
    "significant_columns.append(target_variable)\n",
    "\n",
    "# Create a new filtered list for columns_of_interest\n",
    "columns_of_interest_filtered = [\n",
    "    col for col in columns_of_interest if col in significant_columns\n",
    "]\n",
    "\n",
    "# Display before and after\n",
    "print(f\"Original columns count: {len(columns_of_interest)}\")\n",
    "print(f\"Filtered columns count: {len(columns_of_interest_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[columns_of_interest_filtered]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Running regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['Q6ax1_1'] = filtered_df['Q6ax1_1'].fillna(0)\n",
    "filtered_df['Q6ax3_2'] = filtered_df['Q6ax3_2'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checking if any feature column is missing data...\")\n",
    "print(filtered_df.isnull().sum())\n",
    "\n",
    "print(\"\\nChecking unique values in target variable (Q10_2):\")\n",
    "print(filtered_df[target_variable].unique())\n",
    "\n",
    "print(\"\\nChecking number of non-missing rows in dataset:\")\n",
    "valid_rows = filtered_df.dropna().shape[0]\n",
    "print(f\"Valid rows: {valid_rows} / {df.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's confirm all columns in columns_of_interest_filtered have a transformer\n",
    "for col in columns_of_interest_filtered:\n",
    "    transformer_func = TRANSFORMERS_q6a.get(col, fallback_text_to_float)\n",
    "    print(f\"Column {col}: transformer = {transformer_func.__name__ if transformer_func else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['Q10_2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['Q10_2'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "711/1358"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_binary, X_train, y_train, X_test, y_test = build_v2g_model_binary_from_df(\n",
    "    filtered_df,  \n",
    "    columns_of_interest_filtered,  # Keep same features\n",
    "    target_variable,  \n",
    "    TRANSFORMERS_q6a,  \n",
    "    do_normalize=True,\n",
    "    test_split_ratio=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Visualisation of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final X shape:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model_binary.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coefficients\n",
    "coefs_binary = model_binary.coef_[0]  # Shape: (1, n_features), so take [0]\n",
    "\n",
    "# Create DataFrame for visualization\n",
    "coefs_binary_df = pd.DataFrame({'Feature': columns_of_interest_filtered, 'Coefficient': coefs_binary})\n",
    "coefs_binary_df.sort_values(by=\"Coefficient\", ascending=False, inplace=True)\n",
    "coefs_binary_df[\"Feature\"] = coefs_binary_df[\"Feature\"].map(feature_label_map)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=\"Coefficient\", y=\"Feature\", data=coefs_binary_df, palette=\"coolwarm\")\n",
    "plt.title(\"Effect size in Predicting V2G Adoption (Binary Logistic Regression)\")\n",
    "plt.xlabel(\"Coefficient Value (Log Odds)\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.axvline(x=0, color='black', linestyle='--')  # Reference line for neutral impact\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Odds Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_binary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Compute Odds Ratio\n",
    "coefs_binary_df[\"Odds Ratio\"] = np.exp(coefs_binary_df[\"Coefficient\"])\n",
    "\n",
    "# 2. Sort by Odds Ratio if you prefer (so that the strongest effects appear at the top/bottom)\n",
    "coefs_binary_df.sort_values(by=\"Odds Ratio\", ascending=False, inplace=True)\n",
    "\n",
    "# 3. Plot using Odds Ratio\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=\"Odds Ratio\", y=\"Feature\", data=coefs_binary_df, palette=\"coolwarm\")\n",
    "\n",
    "# 4. Add a vertical reference line at x=1 (since OR=1 means \"no effect\")\n",
    "plt.axvline(x=1, color='black', linestyle='--')\n",
    "\n",
    "# 5. Label and show\n",
    "plt.title(\"Effect size in Predicting V2G Adoption (Binary Logistic Regression)\")\n",
    "plt.xlabel(\"Odds Ratio\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort features by absolute coefficient magnitude for better visualization\n",
    "coefs_binary_df[\"abs_coef\"] = coefs_binary_df[\"Coefficient\"].abs()\n",
    "coefs_binary_df = coefs_binary_df.sort_values(by=\"abs_coef\", ascending=False)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=\"Coefficient\", y=\"Feature\", data=coefs_binary_df, palette=\"coolwarm\")\n",
    "plt.title(\"Feature Importance in Predicting V2G Adoption (Binary Logistic Regression)\")\n",
    "plt.xlabel(\"Coefficient Value (Log Odds)\")\n",
    "plt.ylabel(\"Feature (Survey Question)\")\n",
    "plt.axvline(x=0, color='black', linestyle='--')  # Reference line for neutral impact\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "y_pred_binary = model_binary.predict(X_test)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy_binary = accuracy_score(y_test, y_pred_binary)\n",
    "print(f\"Model Accuracy: {accuracy_binary:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_binary = confusion_matrix(y_test, y_pred_binary, labels=[0, 1])\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_binary, display_labels=[\"Not Adopting\", \"Adopting\"])\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix: Binary V2G Adoption Prediction\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df[\"Q1_2\"] == 0, q6a_ev] = 0  # Set EV charging times to 0 if they don't own an EV\n",
    "df.loc[df[\"Q1_1\"] == 0, q6a_petrol] = 0  # Set Petrol charging times to 0 if they don't own a Petrol car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_rows = df[significant_columns + [target_variable]].dropna().shape[0]\n",
    "print(f\"Valid rows: {valid_rows} / {df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model with binary logistic regression\n",
    "model_binary, X_train, y_train, X_test, y_test = build_v2g_model_binary_from_df(\n",
    "    df,  \n",
    "    significant_columns,  # Keep same features\n",
    "    target_variable,  \n",
    "    TRANSFORMERS_q6a,  \n",
    "    do_normalize=True,\n",
    "    test_split_ratio=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coefficients\n",
    "coefs_binary = model_binary.coef_[0]  # Shape: (1, n_features), so take [0]\n",
    "\n",
    "# Create DataFrame for visualization\n",
    "coefs_binary_df = pd.DataFrame({'Feature': significant_columns, 'Coefficient': coefs_binary})\n",
    "coefs_binary_df.sort_values(by=\"Coefficient\", ascending=False, inplace=True)\n",
    "coefs_binary_df[\"Feature\"] = coefs_binary_df[\"Feature\"].map(feature_label_map)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=\"Coefficient\", y=\"Feature\", data=coefs_binary_df, palette=\"coolwarm\")\n",
    "plt.title(\"Feature Importance in Predicting V2G Adoption (Binary Logistic Regression)\")\n",
    "plt.xlabel(\"Coefficient Value (Log Odds)\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.axvline(x=0, color='black', linestyle='--')  # Reference line for neutral impact\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_binary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make a copy of the dataframe to transform\n",
    "transformed_df = filtered_df.copy()\n",
    "\n",
    "# Apply transformers to all columns in the dataframe\n",
    "for col in transformed_df.columns:\n",
    "    if col in TRANSFORMERS:  # Check if a transformer exists for the column\n",
    "        transformed_df[col] = transformed_df[col].apply(TRANSFORMERS[col])\n",
    "\n",
    "# Ensure numeric values (in case any errors occurred)\n",
    "transformed_df = transformed_df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = transformed_df.corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(corr_matrix, cmap=\"coolwarm\", annot=True, fmt=\".2f\", vmin=-1, vmax=1)\n",
    "plt.title(\"Correlation Matrix of Transformed Features\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
