{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Need to move TRANSFORMERS and text_to_code_q6 to other script\n",
    "from build_model_multinomial import TRANSFORMERS, text_to_code_q6, text_to_code_q10_2_binary, fallback_text_to_float\n",
    "from build_model_logistic import build_v2g_model_binary_from_df, run_single_feature_regressions, filter_significant_features\n",
    "from get_data import init_column_map, pull_data_rowwise\n",
    "\n",
    "from logistic_results_plot import (\n",
    "    plot_feature_significance, \n",
    "    plot_coefficients_barh_by_abscoef, \n",
    "    plot_odds_ratio_barh, \n",
    "    plot_p_value_barh, \n",
    "    plot_log_p_value_barh, \n",
    "    plot_coefficients_significance_barh, \n",
    "    plot_coefficient_vs_significance,\n",
    "    plot_coefficients_barplot,\n",
    "    plot_odds_ratios_barplot,\n",
    "    plot_coefficients_by_abs,\n",
    "    plot_binary_confusion_matrix,\n",
    "    transform_and_plot_correlation\n",
    ")\n",
    "\n",
    "from segmentation import filter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define all variable categories\n",
    "from variables import (\n",
    "    demographics, \n",
    "    input_variables_vehicle_ownership, \n",
    "    familiarity, \n",
    "    kms_driven, \n",
    "    renewables_at_home,\n",
    "    parking, \n",
    "    q6a_cols, \n",
    "    energ_literacy, \n",
    "    renewables_at_home, \n",
    "    intent_to_purchase_vehicle,\n",
    "    benefits_v2g, \n",
    "    concerns_v2g, \n",
    "    interest_in_services, \n",
    "    consider_using_NRMA_for,\n",
    "    charging_control, \n",
    "    preference_on_batt_use, \n",
    "    expected_return,\n",
    "    q6a_petrol, q6a_ev, q6a_plughyb, q6a_hybrid,\n",
    "#     charging_control,\n",
    "    feature_label_map\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Initialise dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = './data/survey_pre_processed_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = 'Q10_2'  # \"I would be interested in installing V2G...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "q10_2_categories = [\n",
    "    \"Strongly disagree\",\n",
    "    \"Somewhat disagree\",\n",
    "    \"Neither agree nor disagree\",\n",
    "    \"Somewhat agree\",\n",
    "    \"Strongly agree\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q8_1</th>\n",
       "      <th>Q8_2</th>\n",
       "      <th>Q8_99</th>\n",
       "      <th>Q6ax1_1</th>\n",
       "      <th>Q6ax1_2</th>\n",
       "      <th>Q6ax1_3</th>\n",
       "      <th>Q6ax2_1</th>\n",
       "      <th>Q6ax2_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Q15_6</th>\n",
       "      <th>Q15_7</th>\n",
       "      <th>Q15_8</th>\n",
       "      <th>Q15_9</th>\n",
       "      <th>Q15_10</th>\n",
       "      <th>Q15_99</th>\n",
       "      <th>Q7_1</th>\n",
       "      <th>Q7_2</th>\n",
       "      <th>Q7_3</th>\n",
       "      <th>Q10_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Somewhat familiar</td>\n",
       "      <td>Less than 10,000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Neither agree nor disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Very familiar</td>\n",
       "      <td>Less than 10,000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Strongly agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not at all familiar</td>\n",
       "      <td>20,001-50,000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Strongly disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not at all familiar</td>\n",
       "      <td>Less than 10,000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Somewhat disagree</td>\n",
       "      <td>Somewhat disagree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Somewhat disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very familiar</td>\n",
       "      <td>20,001-50,000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>Somewhat familiar</td>\n",
       "      <td>10,000-20,000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Neither agree nor disagree</td>\n",
       "      <td>Strongly agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>Somewhat familiar</td>\n",
       "      <td>Less than 10,000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Neither agree nor disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>Very familiar</td>\n",
       "      <td>10,000-20,000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Neither agree nor disagree</td>\n",
       "      <td>Neither agree nor disagree</td>\n",
       "      <td>Strongly agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>Very familiar</td>\n",
       "      <td>10,000-20,000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Neither agree nor disagree</td>\n",
       "      <td>Neither agree nor disagree</td>\n",
       "      <td>Neither agree nor disagree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>Very familiar</td>\n",
       "      <td>20,001-50,000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Somewhat disagree</td>\n",
       "      <td>Strongly disagree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1358 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Q9                Q2 Q8_1 Q8_2 Q8_99 Q6ax1_1 Q6ax1_2  \\\n",
       "0       Somewhat familiar  Less than 10,000    1    0     0       3       5   \n",
       "1           Very familiar  Less than 10,000    1    1     0       5       5   \n",
       "2     Not at all familiar     20,001-50,000    0    0     1       2       1   \n",
       "3     Not at all familiar  Less than 10,000    0    0     1                   \n",
       "4           Very familiar     20,001-50,000    1    1     0       5       5   \n",
       "...                   ...               ...  ...  ...   ...     ...     ...   \n",
       "1353    Somewhat familiar     10,000-20,000    1    1     0                   \n",
       "1354    Somewhat familiar  Less than 10,000    0    0     1       5       5   \n",
       "1355        Very familiar     10,000-20,000    1    0     0       4       4   \n",
       "1356        Very familiar     10,000-20,000    0    0     1                   \n",
       "1357        Very familiar     20,001-50,000    1    1     0                   \n",
       "\n",
       "     Q6ax1_3 Q6ax2_1 Q6ax2_2  ... Q15_6 Q15_7 Q15_8 Q15_9 Q15_10 Q15_99  \\\n",
       "0          5                  ...     1     0     0     0      0      0   \n",
       "1          5       5       5  ...     0     0     0     0      0      1   \n",
       "2          2                  ...     0     0     0     0      0      0   \n",
       "3                             ...     0     0     0     0      0      0   \n",
       "4          5       4       4  ...     0     1     0     0      0      0   \n",
       "...      ...     ...     ...  ...   ...   ...   ...   ...    ...    ...   \n",
       "1353               1       3  ...     1     1     0     0      0      0   \n",
       "1354       5                  ...     0     0     1     0      1      0   \n",
       "1355       5       4       4  ...     0     1     0     0      1      0   \n",
       "1356               3       5  ...     0     0     0     0      1      0   \n",
       "1357               2       5  ...     1     0     0     1      1      0   \n",
       "\n",
       "                            Q7_1                        Q7_2  \\\n",
       "0                 Somewhat agree              Somewhat agree   \n",
       "1                 Strongly agree              Strongly agree   \n",
       "2                 Somewhat agree              Somewhat agree   \n",
       "3              Somewhat disagree           Somewhat disagree   \n",
       "4                 Strongly agree              Strongly agree   \n",
       "...                          ...                         ...   \n",
       "1353              Strongly agree              Strongly agree   \n",
       "1354              Strongly agree              Somewhat agree   \n",
       "1355              Strongly agree  Neither agree nor disagree   \n",
       "1356  Neither agree nor disagree  Neither agree nor disagree   \n",
       "1357              Strongly agree              Somewhat agree   \n",
       "\n",
       "                            Q7_3                       Q10_2  \n",
       "0                 Somewhat agree  Neither agree nor disagree  \n",
       "1                 Somewhat agree              Strongly agree  \n",
       "2                 Somewhat agree           Strongly disagree  \n",
       "3                 Somewhat agree           Somewhat disagree  \n",
       "4                 Somewhat agree              Somewhat agree  \n",
       "...                          ...                         ...  \n",
       "1353  Neither agree nor disagree              Strongly agree  \n",
       "1354              Somewhat agree  Neither agree nor disagree  \n",
       "1355  Neither agree nor disagree              Strongly agree  \n",
       "1356  Neither agree nor disagree              Somewhat agree  \n",
       "1357           Somewhat disagree           Strongly disagree  \n",
       "\n",
       "[1358 rows x 59 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pull the data from CSV\n",
    "init_column_map(csv_file)\n",
    "\n",
    "# TBD -> Make function here\n",
    "columns_of_interest = (\n",
    "    familiarity +\n",
    "    kms_driven + \n",
    "    renewables_at_home + \n",
    "    q6a_cols + \n",
    "    demographics + \n",
    "    input_variables_vehicle_ownership + \n",
    "    parking + \n",
    "    benefits_v2g + \n",
    "    concerns_v2g +\n",
    "    energ_literacy +\n",
    "#   charging_control +\n",
    "    [target_variable]\n",
    "    )\n",
    "\n",
    "rows = pull_data_rowwise(columns_of_interest, csv_file)\n",
    "\n",
    "# Make a DataFrame\n",
    "df = pd.DataFrame(rows, columns=columns_of_interest)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nHere\\'s the only thing different from previous notebook.\\nWe\\'ll consider a segmentation based on a question (or combination of)\\n\\ne.g.:\\nsegment_1_filters = [\"Q1_2 == \\'1\\'\", \"(Q3_1 == \\'1\\') | (Q3_2 == \\'1\\')\"]\\nor\\nfilters = [\"Q1_2 == \\'1\\'\"]\\n\\n'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "Here's the only thing different from previous notebook.\n",
    "We'll consider a segmentation based on a question (or combination of)\n",
    "\n",
    "e.g.:\n",
    "segment_1_filters = [\"Q1_2 == '1'\", \"(Q3_1 == '1') | (Q3_2 == '1')\"]\n",
    "or\n",
    "filters = [\"Q1_2 == '1'\"]\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[input_variables_vehicle_ownership] = df[input_variables_vehicle_ownership].apply(pd.to_numeric, errors='coerce')\n",
    "#df[renewables_at_home] = df[renewables_at_home].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [\n",
    "    \"(Q1_2 == '1') & \"\n",
    "    \"((Q22 == 'Own outright') | (Q22 == 'Own with mortgage')) & \"\n",
    "    \"((Q21 == 'Townhouse') | (Q21 == 'Freestanding house') | (Q21 == 'Semidetached or terrace')) & \"\n",
    "    \"(Q8_1 == '1')\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EV owners\n",
    "df = filter_data(df, filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in Q6ax1_1: [5. 2. 0. 3. 4. 1.]\n",
      "Unique values in Q6ax1_2: [5. 2. 4. 3. 0. 1.]\n",
      "Unique values in Q6ax1_3: [5. 4. 0. 3. 1.]\n",
      "Unique values in Q6ax2_1: [5 4 1 3 2 0]\n",
      "Unique values in Q6ax2_2: [5 4 3 2 0 1]\n",
      "Unique values in Q6ax2_3: [5 4 3 1 0 2]\n",
      "Unique values in Q6ax3_1: [3. 1. 2. 4. 5.]\n",
      "Unique values in Q6ax3_2: [5.]\n",
      "Unique values in Q6ax3_3: [5.]\n",
      "Unique values in Q6ax4_1: [2. 0. 5. 4. 3. 1.]\n",
      "Unique values in Q6ax4_2: [2. 0. 4. 5. 3. 1.]\n",
      "Unique values in Q6ax4_3: [5. 0. 1. 4.]\n"
     ]
    }
   ],
   "source": [
    "# Ensure \"0 - Weekdays\" is converted correctly\n",
    "for col in q6a_cols:\n",
    "    df[col] = df[col].replace(\"0 - Weekdays\", 0)  # Convert \"0 - Weekdays\" to 0\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')  # Convert all values to numbers\n",
    "\n",
    "# Debugging: Check unique values in each column\n",
    "for col in q6a_cols:\n",
    "    print(f\"Unique values in {col}: {df[col].dropna().unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q8_1</th>\n",
       "      <th>Q8_2</th>\n",
       "      <th>Q8_99</th>\n",
       "      <th>Q6ax1_1</th>\n",
       "      <th>Q6ax1_2</th>\n",
       "      <th>Q6ax1_3</th>\n",
       "      <th>Q6ax2_1</th>\n",
       "      <th>Q6ax2_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Q15_6</th>\n",
       "      <th>Q15_7</th>\n",
       "      <th>Q15_8</th>\n",
       "      <th>Q15_9</th>\n",
       "      <th>Q15_10</th>\n",
       "      <th>Q15_99</th>\n",
       "      <th>Q7_1</th>\n",
       "      <th>Q7_2</th>\n",
       "      <th>Q7_3</th>\n",
       "      <th>Q10_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Very familiar</td>\n",
       "      <td>Less than 10,000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Strongly agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very familiar</td>\n",
       "      <td>20,001-50,000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Very familiar</td>\n",
       "      <td>20,001-50,000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Strongly agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Somewhat familiar</td>\n",
       "      <td>10,000-20,000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Neither agree nor disagree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Very familiar</td>\n",
       "      <td>10,000-20,000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>Somewhat familiar</td>\n",
       "      <td>10,000-20,000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Somewhat disagree</td>\n",
       "      <td>Strongly agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>Very familiar</td>\n",
       "      <td>10,000-20,000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Strongly agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>Somewhat familiar</td>\n",
       "      <td>10,000-20,000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Neither agree nor disagree</td>\n",
       "      <td>Strongly agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>Very familiar</td>\n",
       "      <td>10,000-20,000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Neither agree nor disagree</td>\n",
       "      <td>Neither agree nor disagree</td>\n",
       "      <td>Strongly agree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>Very familiar</td>\n",
       "      <td>20,001-50,000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Strongly agree</td>\n",
       "      <td>Somewhat agree</td>\n",
       "      <td>Somewhat disagree</td>\n",
       "      <td>Strongly disagree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>557 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Q9                Q2  Q8_1  Q8_2  Q8_99  Q6ax1_1  \\\n",
       "1         Very familiar  Less than 10,000     1     1      0      5.0   \n",
       "4         Very familiar     20,001-50,000     1     1      0      5.0   \n",
       "5         Very familiar     20,001-50,000     1     0      0      5.0   \n",
       "10    Somewhat familiar     10,000-20,000     1     0      0      2.0   \n",
       "11        Very familiar     10,000-20,000     1     1      0      NaN   \n",
       "...                 ...               ...   ...   ...    ...      ...   \n",
       "1351  Somewhat familiar     10,000-20,000     1     1      0      NaN   \n",
       "1352      Very familiar     10,000-20,000     1     0      0      NaN   \n",
       "1353  Somewhat familiar     10,000-20,000     1     1      0      NaN   \n",
       "1355      Very familiar     10,000-20,000     1     0      0      4.0   \n",
       "1357      Very familiar     20,001-50,000     1     1      0      NaN   \n",
       "\n",
       "      Q6ax1_2  Q6ax1_3  Q6ax2_1  Q6ax2_2  ...  Q15_6  Q15_7  Q15_8  Q15_9  \\\n",
       "1         5.0      5.0        5        5  ...      0      0      0      0   \n",
       "4         5.0      5.0        4        4  ...      0      1      0      0   \n",
       "5         5.0      5.0        5        5  ...      0      0      1      0   \n",
       "10        2.0      5.0        1        3  ...      1      1      0      0   \n",
       "11        NaN      NaN        3        4  ...      1      0      0      0   \n",
       "...       ...      ...      ...      ...  ...    ...    ...    ...    ...   \n",
       "1351      NaN      NaN        3        5  ...      0      1      1      0   \n",
       "1352      NaN      NaN        2        3  ...      0      1      0      0   \n",
       "1353      NaN      NaN        1        3  ...      1      1      0      0   \n",
       "1355      4.0      5.0        4        4  ...      0      1      0      0   \n",
       "1357      NaN      NaN        2        5  ...      1      0      0      1   \n",
       "\n",
       "      Q15_10  Q15_99            Q7_1                        Q7_2  \\\n",
       "1          0       1  Strongly agree              Strongly agree   \n",
       "4          0       0  Strongly agree              Strongly agree   \n",
       "5          0       0  Strongly agree              Strongly agree   \n",
       "10         0       0  Strongly agree              Strongly agree   \n",
       "11         0       0  Somewhat agree              Somewhat agree   \n",
       "...      ...     ...             ...                         ...   \n",
       "1351       0       0  Strongly agree              Somewhat agree   \n",
       "1352       1       0  Strongly agree              Strongly agree   \n",
       "1353       0       0  Strongly agree              Strongly agree   \n",
       "1355       1       0  Strongly agree  Neither agree nor disagree   \n",
       "1357       1       0  Strongly agree              Somewhat agree   \n",
       "\n",
       "                            Q7_3                       Q10_2  \n",
       "1                 Somewhat agree              Strongly agree  \n",
       "4                 Somewhat agree              Somewhat agree  \n",
       "5                 Somewhat agree              Strongly agree  \n",
       "10                Somewhat agree  Neither agree nor disagree  \n",
       "11                Somewhat agree              Somewhat agree  \n",
       "...                          ...                         ...  \n",
       "1351           Somewhat disagree              Strongly agree  \n",
       "1352              Somewhat agree              Strongly agree  \n",
       "1353  Neither agree nor disagree              Strongly agree  \n",
       "1355  Neither agree nor disagree              Strongly agree  \n",
       "1357           Somewhat disagree           Strongly disagree  \n",
       "\n",
       "[557 rows x 59 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of responses recorded as 0:\n",
      "Q6ax1_1    27\n",
      "Q6ax1_2     6\n",
      "Q6ax1_3     8\n",
      "Q6ax2_1    67\n",
      "Q6ax2_2    17\n",
      "Q6ax2_3    11\n",
      "Q6ax3_1     0\n",
      "Q6ax3_2     0\n",
      "Q6ax3_3     0\n",
      "Q6ax4_1     5\n",
      "Q6ax4_2     2\n",
      "Q6ax4_3     2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count missing responses for each charging question\n",
    "missing_counts = (df[q6a_cols] == 0).sum()\n",
    "# Display summary of non-responses per column\n",
    "print(\"Number of responses recorded as 0:\")\n",
    "print(missing_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q6ax1_1    265\n",
      "Q6ax1_2    265\n",
      "Q6ax1_3    265\n",
      "Q6ax2_1    557\n",
      "Q6ax2_2    557\n",
      "Q6ax2_3    557\n",
      "Q6ax3_1      8\n",
      "Q6ax3_2      8\n",
      "Q6ax3_3      8\n",
      "Q6ax4_1     30\n",
      "Q6ax4_2     30\n",
      "Q6ax4_3     30\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking number of vehicles per type\n",
    "print(df[q6a_petrol + q6a_ev + q6a_plughyb + q6a_hybrid].notna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Update transformers to consider Q10_2 as binary (other than multinomial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of TRANSFORMERS and update it with Q6a mappings\n",
    "TRANSFORMERS_q6a = TRANSFORMERS.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update with Q6a_* variables (charging behavior questions)\n",
    "TRANSFORMERS_q6a.update({\n",
    "    **{q: text_to_code_q6 for q in q6a_petrol},  \n",
    "    **{q: text_to_code_q6 for q in q6a_ev},      \n",
    "    **{q: text_to_code_q6 for q in q6a_plughyb}, \n",
    "    **{q: text_to_code_q6 for q in q6a_hybrid}   \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1_1': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q1_2': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q1_3': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q1_4': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q1_99': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q2': <function build_model_multinomial.text_to_code_q2(raw_ans)>,\n",
       " 'Q3_1': <function build_model_multinomial.text_to_code_q3_parking(raw_ans)>,\n",
       " 'Q3_2': <function build_model_multinomial.text_to_code_q3_parking(raw_ans)>,\n",
       " 'Q3_3': <function build_model_multinomial.text_to_code_q3_parking(raw_ans)>,\n",
       " 'Q3_4': <function build_model_multinomial.text_to_code_q3_parking(raw_ans)>,\n",
       " 'Q3_5': <function build_model_multinomial.text_to_code_q3_parking(raw_ans)>,\n",
       " 'Q7_1': <function build_model_multinomial.text_to_code_q7_likert(raw_ans)>,\n",
       " 'Q7_2': <function build_model_multinomial.text_to_code_q7_likert(raw_ans)>,\n",
       " 'Q7_3': <function build_model_multinomial.text_to_code_q7_likert(raw_ans)>,\n",
       " 'Q8_1': <function build_model_multinomial.text_to_code_q8_multi(raw_ans)>,\n",
       " 'Q8_2': <function build_model_multinomial.text_to_code_q8_multi(raw_ans)>,\n",
       " 'Q8_99': <function build_model_multinomial.text_to_code_q8_multi(raw_ans)>,\n",
       " 'Q9': <function build_model_multinomial.text_to_code_q9(raw_ans)>,\n",
       " 'Q10_2': <function build_model_multinomial.text_to_code_q10_2_binary(raw_ans)>,\n",
       " 'Q14_1': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q14_2': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q14_3': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q14_4': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q14_5': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q14_6': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q14_7': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q14_8': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q14_99': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q15_1': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q15_2': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q15_3': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q15_4': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q15_5': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q15_6': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q15_7': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q15_8': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q15_9': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q15_10': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q15_99': <function build_model_multinomial.text_to_code_binary(raw_ans)>,\n",
       " 'Q17_1': <function build_model_multinomial.text_to_code_q17_rank_for_first(raw_ans)>,\n",
       " 'Q17_2': <function build_model_multinomial.text_to_code_q17_rank_for_first(raw_ans)>,\n",
       " 'Q17_3': <function build_model_multinomial.text_to_code_q17_rank_for_first(raw_ans)>,\n",
       " 'Q6ax1_1': <function build_model_multinomial.text_to_code_q6(raw_ans)>,\n",
       " 'Q6ax1_2': <function build_model_multinomial.text_to_code_q6(raw_ans)>,\n",
       " 'Q6ax1_3': <function build_model_multinomial.text_to_code_q6(raw_ans)>,\n",
       " 'Q6ax2_1': <function build_model_multinomial.text_to_code_q6(raw_ans)>,\n",
       " 'Q6ax2_2': <function build_model_multinomial.text_to_code_q6(raw_ans)>,\n",
       " 'Q6ax2_3': <function build_model_multinomial.text_to_code_q6(raw_ans)>,\n",
       " 'Q6ax3_1': <function build_model_multinomial.text_to_code_q6(raw_ans)>,\n",
       " 'Q6ax3_2': <function build_model_multinomial.text_to_code_q6(raw_ans)>,\n",
       " 'Q6ax3_3': <function build_model_multinomial.text_to_code_q6(raw_ans)>,\n",
       " 'Q6ax4_1': <function build_model_multinomial.text_to_code_q6(raw_ans)>,\n",
       " 'Q6ax4_2': <function build_model_multinomial.text_to_code_q6(raw_ans)>,\n",
       " 'Q6ax4_3': <function build_model_multinomial.text_to_code_q6(raw_ans)>}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSFORMERS_q6a[target_variable] = text_to_code_q10_2_binary\n",
    "TRANSFORMERS_q6a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Selection - Univariate Logistic Regression Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_select = (\n",
    "    familiarity + \n",
    "    kms_driven +\n",
    "    renewables_at_home +\n",
    "    input_variables_vehicle_ownership + \n",
    "    q6a_petrol + \n",
    "    q6a_ev + \n",
    "    q6a_hybrid +\n",
    "    q6a_plughyb +\n",
    "    parking +\n",
    "    benefits_v2g + \n",
    "    concerns_v2g + \n",
    "#   charging_control +\n",
    "    energ_literacy\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[target_variable] = df[target_variable].apply(text_to_code_q10_2_binary)\n",
    "\n",
    "# Ensure the target variable is binary (0 or 1)\n",
    "df[target_variable] = df[target_variable].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Vehicle at home habits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per Q6a variable:\n",
      " Q6ax1_1    292\n",
      "Q6ax1_2    292\n",
      "Q6ax1_3    292\n",
      "Q6ax2_1      0\n",
      "Q6ax2_2      0\n",
      "Q6ax2_3      0\n",
      "Q6ax3_1    549\n",
      "Q6ax3_2    549\n",
      "Q6ax3_3    549\n",
      "Q6ax4_1    527\n",
      "Q6ax4_2    527\n",
      "Q6ax4_3    527\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_q6a = df[q6a_cols].isna().sum()\n",
    "print(\"Missing values per Q6a variable:\\n\", missing_q6a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[q6a_cols] = df[q6a_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in Q6ax1_1: [5. 2. 0. 3. 4. 1.]\n",
      "Unique values in Q6ax1_2: [5. 2. 0. 4. 3. 1.]\n",
      "Unique values in Q6ax1_3: [5. 0. 4. 3. 1.]\n",
      "Unique values in Q6ax2_1: [5 4 1 3 2 0]\n",
      "Unique values in Q6ax2_2: [5 4 3 2 0 1]\n",
      "Unique values in Q6ax2_3: [5 4 3 1 0 2]\n",
      "Unique values in Q6ax3_1: [0. 3. 1. 2. 4. 5.]\n",
      "Unique values in Q6ax3_2: [0. 5.]\n",
      "Unique values in Q6ax3_3: [0. 5.]\n",
      "Unique values in Q6ax4_1: [0. 2. 5. 4. 3. 1.]\n",
      "Unique values in Q6ax4_2: [0. 2. 4. 5. 3. 1.]\n",
      "Unique values in Q6ax4_3: [0. 5. 1. 4.]\n"
     ]
    }
   ],
   "source": [
    "for col in q6a_cols:\n",
    "    print(f\"Unique values in {col}: {df[col].dropna().unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "q6a_filters = {\n",
    "    \"petrol\": (df[\"Q1_1\"].astype(int) == 1),\n",
    "    \"ev\": (df[\"Q1_2\"].astype(int) == 1),\n",
    "    \"plug_hybrid\": (df[\"Q1_3\"].astype(int) == 1),\n",
    "    \"hybrid\": (df[\"Q1_4\"].astype(int) == 1),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Single feature regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Logistic Regression for: Q9\n",
      "Total rows before filter: 557\n",
      "Valid rows after filtering: 557\n",
      "Running Logistic Regression for: Q2\n",
      "Total rows before filter: 557\n",
      "Valid rows after filtering: 557\n",
      "Running Logistic Regression for: Q8_1\n",
      "Total rows before filter: 557\n",
      "Valid rows after filtering: 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by LogisticRegression.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [108], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m results_df \u001b[38;5;241m=\u001b[39m \u001b[43mrun_single_feature_regressions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures_to_select\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures_to_select\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_variable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mQ10_2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq6a_petrol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq6a_petrol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq6a_ev\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq6a_ev\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq6a_plughyb\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq6a_plughyb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq6a_hybrid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq6a_hybrid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mq6a_filters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq6a_filters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mTRANSFORMERS_q6a\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRANSFORMERS_q6a\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_label_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_label_map\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\24417507\\OneDrive - UTS\\Documents\\v2g-survey-analysis\\v2g-survey-analysis\\build_model_logistic.py:183\u001b[0m, in \u001b[0;36mrun_single_feature_regressions\u001b[1;34m(df, features_to_select, target_variable, q6a_petrol, q6a_ev, q6a_plughyb, q6a_hybrid, q6a_filters, TRANSFORMERS_q6a, feature_label_map)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;66;03m# 6) Fit logistic regression\u001b[39;00m\n\u001b[0;32m    182\u001b[0m model \u001b[38;5;241m=\u001b[39m LogisticRegression(penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m, solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 183\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_single\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[0;32m    186\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_single)\n",
      "File \u001b[1;32mc:\\Users\\24417507\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1138\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m     _dtype \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mfloat64, np\u001b[38;5;241m.\u001b[39mfloat32]\n\u001b[1;32m-> 1138\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1140\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1142\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1146\u001b[0m check_classification_targets(y)\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(y)\n",
      "File \u001b[1;32mc:\\Users\\24417507\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    594\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    597\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Users\\24417507\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1074\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1069\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1070\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1071\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1072\u001b[0m     )\n\u001b[1;32m-> 1074\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1075\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1085\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1086\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1087\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1088\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1090\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1092\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Users\\24417507\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:909\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    907\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[0;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 909\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    910\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    911\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    913\u001b[0m         )\n\u001b[0;32m    915\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    916\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 1)) while a minimum of 1 is required by LogisticRegression."
     ]
    }
   ],
   "source": [
    "results_df = run_single_feature_regressions(\n",
    "    df=df,\n",
    "    features_to_select=features_to_select,\n",
    "    target_variable=\"Q10_2\",\n",
    "    q6a_petrol=q6a_petrol,\n",
    "    q6a_ev=q6a_ev,\n",
    "    q6a_plughyb=q6a_plughyb,\n",
    "    q6a_hybrid=q6a_hybrid,\n",
    "    q6a_filters=q6a_filters,\n",
    "    TRANSFORMERS_q6a=TRANSFORMERS_q6a,\n",
    "    feature_label_map=feature_label_map\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_significance(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coefficients_barh_by_abscoef(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_odds_ratio_barh(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_p_value_barh(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_log_p_value_barh(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coefficients_significance_barh(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coefficient_vs_significance(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Binomial Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Filtering my df based on the previous p-value analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_of_interest_filtered = filter_significant_features(\n",
    "    results_df=results_df,\n",
    "    feature_label_map=feature_label_map,\n",
    "    columns_of_interest=columns_of_interest,\n",
    "    target_variable=target_variable\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[columns_of_interest_filtered]\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Running regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['Q6ax1_1'] = filtered_df['Q6ax1_1'].fillna(0)\n",
    "filtered_df['Q6ax3_2'] = filtered_df['Q6ax3_2'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checking if any feature column is missing data...\")\n",
    "print(filtered_df.isnull().sum())\n",
    "\n",
    "print(\"\\nChecking unique values in target variable (Q10_2):\")\n",
    "print(filtered_df[target_variable].unique())\n",
    "\n",
    "print(\"\\nChecking number of non-missing rows in dataset:\")\n",
    "valid_rows = filtered_df.dropna().shape[0]\n",
    "print(f\"Valid rows: {valid_rows} / {df.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's confirm all columns in columns_of_interest_filtered have a transformer\n",
    "for col in columns_of_interest_filtered:\n",
    "    transformer_func = TRANSFORMERS_q6a.get(col, fallback_text_to_float)\n",
    "    print(f\"Column {col}: transformer = {transformer_func.__name__ if transformer_func else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_binary, X_train, y_train, X_test, y_test = build_v2g_model_binary_from_df(\n",
    "    filtered_df,  \n",
    "    columns_of_interest_filtered,\n",
    "    target_variable,  \n",
    "    TRANSFORMERS_q6a,  \n",
    "    do_normalize=True,\n",
    "    test_split_ratio=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Visualisation of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coefficients\n",
    "coefs_binary = model_binary.coef_[0]  # Shape: (1, n_features), so take [0]\n",
    "\n",
    "# Create DataFrame for visualization\n",
    "coefs_binary_df = pd.DataFrame({'Feature': columns_of_interest_filtered, 'Coefficient': coefs_binary})\n",
    "coefs_binary_df.sort_values(by=\"Coefficient\", ascending=False, inplace=True)\n",
    "coefs_binary_df[\"Feature\"] = coefs_binary_df[\"Feature\"].map(feature_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coefficients_barplot(coefs_binary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Odds Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_binary_df[\"Odds Ratio\"] = np.exp(coefs_binary_df[\"Coefficient\"])\n",
    "coefs_binary_df.sort_values(by=\"Odds Ratio\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_odds_ratios_barplot(coefs_binary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort features by absolute coefficient magnitude for better visualization\n",
    "coefs_binary_df[\"abs_coef\"] = coefs_binary_df[\"Coefficient\"].abs()\n",
    "coefs_binary_df = coefs_binary_df.sort_values(by=\"abs_coef\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_coefficients_by_abs(coefs_binary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data\n",
    "y_pred_binary = model_binary.predict(X_test)\n",
    "# Compute accuracy\n",
    "accuracy_binary = accuracy_score(y_test, y_pred_binary)\n",
    "print(f\"Model Accuracy: {accuracy_binary:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_binary_confusion_matrix(y_test, y_pred_binary, labels=[\"Not Adopting\", \"Adopting\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = transform_and_plot_correlation(\n",
    "    filtered_df, \n",
    "    TRANSFORMERS,\n",
    "    figsize=(20, 16),\n",
    "    title=\"Correlation Matrix of Transformed Features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
